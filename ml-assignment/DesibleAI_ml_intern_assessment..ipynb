{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xU-4JGTnm5Bl",
        "outputId": "219d504b-c08b-42ee-e4ba-59a2586562db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-intern-assessment'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 20 (delta 1), reused 0 (delta 0), pack-reused 14 (from 1)\u001b[K\n",
            "Receiving objects: 100% (20/20), 5.35 KiB | 2.68 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/ml-intern-assessment/ml-assignment\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DesibleAI/ml-intern-assessment.git\n",
        "%cd ml-intern-assessment/ml-assignment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joMVvJAinAqU",
        "outputId": "392003e9-d079-43a5-ec38-8a207589b819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_corpus.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/example_corpus.txt\", \"r\") as f:\n",
        "    corpus = f.readlines()\n",
        "\n",
        "corpus[:10]  # show first 10 lines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWjI0fnlnAtQ",
        "outputId": "4055d5d8-f47a-4891-869f-7e25503358a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This is an example corpus for the trigram assignment.\\n',\n",
              " 'It contains a few sentences to get you started.\\n',\n",
              " 'You can use this corpus to train and test your trigram model.\\n',\n",
              " 'Feel free to add more text to this file or use your own corpus.\\n',\n",
              " 'The more data you have, the better your model will be.\\n',\n",
              " 'Good luck!\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' src/ngram_model.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G_Fc5qWnAwO",
        "outputId": "f28c4956-52bb-4dac-cf7c-fb1e13b7e871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "\n",
            "class TrigramModel:\n",
            "    def __init__(self):\n",
            "        \"\"\"\n",
            "        Initializes the TrigramModel.\n",
            "        \"\"\"\n",
            "        # TODO: Initialize any data structures you need to store the n-gram counts.\n",
            "       \n",
            "        pass\n",
            "\n",
            "    def fit(self, text):\n",
            "        \"\"\"\n",
            "        Trains the trigram model on the given text.\n",
            "\n",
            "        Args:\n",
            "            text (str): The text to train the model on.\n",
            "        \"\"\"\n",
            "        # TODO: Implement the training logic.\n",
            "        # This will involve:\n",
            "        # 1. Cleaning the text (e.g., converting to lowercase, removing punctuation).\n",
            "        # 2. Tokenizing the text into words.\n",
            "        # 3. Padding the text with start and end tokens.\n",
            "        # 4. Counting the trigrams.\n",
            "        pass\n",
            "\n",
            "    def generate(self, max_length=50):\n",
            "        \"\"\"\n",
            "        Generates new text using the trained trigram model.\n",
            "\n",
            "        Args:\n",
            "            max_length (int): The maximum length of the generated text.\n",
            "\n",
            "        Returns:\n",
            "            str: The generated text.\n",
            "        \"\"\"\n",
            "        # TODO: Implement the generation logic.\n",
            "        # This will involve:\n",
            "        # 1. Starting with the start tokens.\n",
            "        # 2. Probabilistically choosing the next word based on the current context.\n",
            "        # 3. Repeating until the end token is generated or the maximum length is reached.\n",
            "        pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' src/utils.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tal_LEn8nAzl",
        "outputId": "4bc8b633-2f64-46e4-8db8-9c251d3141a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# This file is optional.\n",
            "# You can add any utility functions you need for your implementation here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' src/generate.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPwobYffoa9E",
        "outputId": "217c0c46-0af0-4216-fef6-561c17d261a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from ngram_model import TrigramModel\n",
            "\n",
            "def main():\n",
            "    # Create a new TrigramModel\n",
            "    model = TrigramModel()\n",
            "\n",
            "    # Train the model on the example corpus\n",
            "    with open(\"data/example_corpus.txt\", \"r\") as f:\n",
            "        text = f.read()\n",
            "    model.fit(text)\n",
            "\n",
            "    # Generate new text\n",
            "    generated_text = model.generate()\n",
            "    print(\"Generated Text:\")\n",
            "    print(generated_text)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils.py\n",
        "import re\n",
        "import logging\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans text by:\n",
        "    - converting to lowercase\n",
        "    - removing non-alphanumeric characters\n",
        "    - collapsing multiple spaces\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Keep only alphabets, digits, apostrophes, and spaces\n",
        "    cleaned = re.sub(r\"[^a-z0-9'\\s]+\", \" \", text)\n",
        "\n",
        "    # Normalize multiple spaces\n",
        "    cleaned = \" \".join(cleaned.split())\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Splits cleaned text into tokens.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    \"\"\"\n",
        "    Sets seeds for Python, NumPy (if available), and random for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "\n",
        "    try:\n",
        "        import numpy as np\n",
        "        np.random.seed(seed)\n",
        "    except ImportError:\n",
        "        pass  # NumPy not installed, skip.\n",
        "\n",
        "\n",
        "def get_logger(name: str = \"app_logger\"):\n",
        "    \"\"\"\n",
        "    Returns a simple logger instance with formatting.\n",
        "    Prevents adding duplicate handlers on repeated imports.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(name)\n",
        "\n",
        "    if not logger.handlers:\n",
        "        handler = logging.StreamHandler()\n",
        "        formatter = logging.Formatter(\n",
        "            fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
        "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        "        )\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "\n",
        "    logger.setLevel(logging.INFO)\n",
        "    return logger\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugiup-wHpq5k",
        "outputId": "0ac86db6-e67d-4dbe-97d9-883131ba6b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' src/utils.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05-Y1bhqruZo",
        "outputId": "71323f88-3ea7-4064-b5f6-def7c764569c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import re\n",
            "import logging\n",
            "import random\n",
            "from typing import List\n",
            "\n",
            "def clean_text(text: str) -> str:\n",
            "    \"\"\"\n",
            "    Cleans text by:\n",
            "    - converting to lowercase\n",
            "    - removing non-alphanumeric characters\n",
            "    - collapsing multiple spaces\n",
            "    \"\"\"\n",
            "    if not isinstance(text, str):\n",
            "        return \"\"\n",
            "\n",
            "    # Lowercase\n",
            "    text = text.lower()\n",
            "\n",
            "    # Keep only alphabets, digits, apostrophes, and spaces\n",
            "    cleaned = re.sub(r\"[^a-z0-9'\\s]+\", \" \", text)\n",
            "\n",
            "    # Normalize multiple spaces\n",
            "    cleaned = \" \".join(cleaned.split())\n",
            "\n",
            "    return cleaned\n",
            "\n",
            "\n",
            "def tokenize(text: str) -> List[str]:\n",
            "    \"\"\"\n",
            "    Splits cleaned text into tokens.\n",
            "    \"\"\"\n",
            "    if not text:\n",
            "        return []\n",
            "    return text.split()\n",
            "\n",
            "\n",
            "def set_seed(seed: int = 42):\n",
            "    \"\"\"\n",
            "    Sets seeds for Python, NumPy (if available), and random for reproducibility.\n",
            "    \"\"\"\n",
            "    random.seed(seed)\n",
            "\n",
            "    try:\n",
            "        import numpy as np\n",
            "        np.random.seed(seed)\n",
            "    except ImportError:\n",
            "        pass  # NumPy not installed, skip.\n",
            "\n",
            "\n",
            "def get_logger(name: str = \"app_logger\"):\n",
            "    \"\"\"\n",
            "    Returns a simple logger instance with formatting.\n",
            "    Prevents adding duplicate handlers on repeated imports.\n",
            "    \"\"\"\n",
            "    logger = logging.getLogger(name)\n",
            "\n",
            "    if not logger.handlers:\n",
            "        handler = logging.StreamHandler()\n",
            "        formatter = logging.Formatter(\n",
            "            fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
            "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
            "        )\n",
            "        handler.setFormatter(formatter)\n",
            "        logger.addHandler(handler)\n",
            "\n",
            "    logger.setLevel(logging.INFO)\n",
            "    return logger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "class TrigramGenerator:\n",
        "    def _init_(self, seed: Optional[int] = None):\n",
        "        self.trigrams: List[Tuple[Tuple[str, str], str]] = []\n",
        "        self.tokens: List[str] = []\n",
        "        if seed is not None:\n",
        "            random.seed(seed)\n",
        "\n",
        "    def _tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"Lowercase, remove punctuation, split into words\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^\\w\\s']\", \" \", text)\n",
        "        return text.split()\n",
        "\n",
        "    def fit(self, text: str):\n",
        "        \"\"\"Build list of trigrams as ((word1, word2), word3)\"\"\"\n",
        "        self.tokens = self._tokenize(text)\n",
        "        self.trigrams = []\n",
        "\n",
        "        for i in range(len(self.tokens) - 2):\n",
        "            key = (self.tokens[i], self.tokens[i + 1])\n",
        "            next_word = self.tokens[i + 2]\n",
        "            self.trigrams.append((key, next_word))\n",
        "\n",
        "    def generate(self, max_words: int = 20, start_bigram: Optional[Tuple[str, str]] = None) -> str:\n",
        "        \"\"\"Generate text using stored trigram list\"\"\"\n",
        "        if not self.tokens or not self.trigrams:\n",
        "            return \" \".join(self.tokens)\n",
        "\n",
        "        # Choose starting bigram\n",
        "        if start_bigram:\n",
        "            candidates = [t for t in self.trigrams if t[0] == start_bigram]\n",
        "            if candidates:\n",
        "                current = random.choice(candidates)\n",
        "            else:\n",
        "                current = random.choice(self.trigrams)\n",
        "        else:\n",
        "            current = random.choice(self.trigrams)\n",
        "\n",
        "        output = [current[0][0], current[0][1], current[1]]\n",
        "\n",
        "        for _ in range(max_words - 3):\n",
        "            # Find all next words that match the last two words\n",
        "            key = (output[-2], output[-1])\n",
        "            next_options = [t[1] for t in self.trigrams if t[0] == key]\n",
        "            if not next_options:\n",
        "                break\n",
        "            output.append(random.choice(next_options))\n",
        "\n",
        "        return \" \".join(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "iPSj8XQepsqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/ngram_model.py\n",
        "import random\n",
        "import re\n",
        "\n",
        "class TrigramModel:\n",
        "    def __init__(self):\n",
        "        self.trigrams = {}\n",
        "        self.tokens = []\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "        tokens = text.split()\n",
        "        return tokens\n",
        "\n",
        "    def fit(self, text):\n",
        "        # Handle empty input\n",
        "        if not text or text.strip() == \"\":\n",
        "            self.tokens = []\n",
        "            self.trigrams = {}\n",
        "            return\n",
        "\n",
        "        # Tokenize\n",
        "        self.tokens = self._tokenize(text)\n",
        "\n",
        "        # Not enough tokens → no trigram possible\n",
        "        if len(self.tokens) < 3:\n",
        "            self.trigrams = {}\n",
        "            return\n",
        "\n",
        "        # Build trigrams\n",
        "        self.trigrams = {}\n",
        "        for i in range(len(self.tokens) - 2):\n",
        "            key = (self.tokens[i], self.tokens[i+1])\n",
        "            next_word = self.tokens[i+2]\n",
        "\n",
        "            if key not in self.trigrams:\n",
        "                self.trigrams[key] = []\n",
        "\n",
        "            self.trigrams[key].append(next_word)\n",
        "\n",
        "    def generate(self, max_words=20):\n",
        "        # For empty text, return empty string (tests expect this)\n",
        "        if not self.tokens:\n",
        "            return \"\"\n",
        "\n",
        "        # If no trigram pairs, still return something\n",
        "        if not self.trigrams:\n",
        "            return \" \".join(self.tokens)\n",
        "\n",
        "        # Start generation from a random bigram\n",
        "        current_bigram = random.choice(list(self.trigrams.keys()))\n",
        "        output_words = [current_bigram[0], current_bigram[1]]\n",
        "\n",
        "        # Generate words\n",
        "        for _ in range(max_words):\n",
        "            next_options = self.trigrams.get(current_bigram)\n",
        "            if not next_options:\n",
        "                break\n",
        "\n",
        "            next_word = random.choice(next_options)\n",
        "            output_words.append(next_word)\n",
        "\n",
        "            current_bigram = (current_bigram[1], next_word)\n",
        "\n",
        "        return \" \".join(output_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORzPcy8NsVg8",
        "outputId": "ca47d608-fb3e-4e3a-aa3b-b4e00446aca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/ngram_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ml-intern-assessment/ml-assignment\n",
        "!ls -R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfA0XKKqpst5",
        "outputId": "b74f74c5-ffd2-426f-e076-a1f5415ce088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ml-intern-assessment/ml-assignment\n",
            ".:\n",
            "data  evaluation.md  README.md\tsrc  tests\n",
            "\n",
            "./data:\n",
            "example_corpus.txt\n",
            "\n",
            "./src:\n",
            "generate.py  ngram_model.py  __pycache__  utils.py\n",
            "\n",
            "./src/__pycache__:\n",
            "ngram_model.cpython-312.pyc\n",
            "\n",
            "./tests:\n",
            "__pycache__  test_ngram.py\n",
            "\n",
            "./tests/__pycache__:\n",
            "test_ngram.cpython-312-pytest-8.4.2.pyc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,200p' src/ngram_model.py\n",
        "!sed -n '1,200p' src/utils.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIaSXEdysbFa",
        "outputId": "bfdff8fe-db2b-4330-a02c-57cb989bf3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "import re\n",
            "\n",
            "class TrigramModel:\n",
            "    def __init__(self):\n",
            "        self.trigrams = {}\n",
            "        self.tokens = []\n",
            "\n",
            "    def _tokenize(self, text):\n",
            "        text = text.lower()\n",
            "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
            "        tokens = text.split()\n",
            "        return tokens\n",
            "\n",
            "    def fit(self, text):\n",
            "        # Handle empty input\n",
            "        if not text or text.strip() == \"\":\n",
            "            self.tokens = []\n",
            "            self.trigrams = {}\n",
            "            return\n",
            "\n",
            "        # Tokenize\n",
            "        self.tokens = self._tokenize(text)\n",
            "\n",
            "        # Not enough tokens → no trigram possible\n",
            "        if len(self.tokens) < 3:\n",
            "            self.trigrams = {}\n",
            "            return\n",
            "\n",
            "        # Build trigrams\n",
            "        self.trigrams = {}\n",
            "        for i in range(len(self.tokens) - 2):\n",
            "            key = (self.tokens[i], self.tokens[i+1])\n",
            "            next_word = self.tokens[i+2]\n",
            "\n",
            "            if key not in self.trigrams:\n",
            "                self.trigrams[key] = []\n",
            "\n",
            "            self.trigrams[key].append(next_word)\n",
            "\n",
            "    def generate(self, max_words=20):\n",
            "        # For empty text, return empty string (tests expect this)\n",
            "        if not self.tokens:\n",
            "            return \"\"\n",
            "\n",
            "        # If no trigram pairs, still return something\n",
            "        if not self.trigrams:\n",
            "            return \" \".join(self.tokens)\n",
            "\n",
            "        # Start generation from a random bigram\n",
            "        current_bigram = random.choice(list(self.trigrams.keys()))\n",
            "        output_words = [current_bigram[0], current_bigram[1]]\n",
            "\n",
            "        # Generate words\n",
            "        for _ in range(max_words):\n",
            "            next_options = self.trigrams.get(current_bigram)\n",
            "            if not next_options:\n",
            "                break\n",
            "\n",
            "            next_word = random.choice(next_options)\n",
            "            output_words.append(next_word)\n",
            "\n",
            "            current_bigram = (current_bigram[1], next_word)\n",
            "\n",
            "        return \" \".join(output_words)\n",
            "import re\n",
            "import logging\n",
            "import random\n",
            "from typing import List\n",
            "\n",
            "def clean_text(text: str) -> str:\n",
            "    \"\"\"\n",
            "    Cleans text by:\n",
            "    - converting to lowercase\n",
            "    - removing non-alphanumeric characters\n",
            "    - collapsing multiple spaces\n",
            "    \"\"\"\n",
            "    if not isinstance(text, str):\n",
            "        return \"\"\n",
            "\n",
            "    # Lowercase\n",
            "    text = text.lower()\n",
            "\n",
            "    # Keep only alphabets, digits, apostrophes, and spaces\n",
            "    cleaned = re.sub(r\"[^a-z0-9'\\s]+\", \" \", text)\n",
            "\n",
            "    # Normalize multiple spaces\n",
            "    cleaned = \" \".join(cleaned.split())\n",
            "\n",
            "    return cleaned\n",
            "\n",
            "\n",
            "def tokenize(text: str) -> List[str]:\n",
            "    \"\"\"\n",
            "    Splits cleaned text into tokens.\n",
            "    \"\"\"\n",
            "    if not text:\n",
            "        return []\n",
            "    return text.split()\n",
            "\n",
            "\n",
            "def set_seed(seed: int = 42):\n",
            "    \"\"\"\n",
            "    Sets seeds for Python, NumPy (if available), and random for reproducibility.\n",
            "    \"\"\"\n",
            "    random.seed(seed)\n",
            "\n",
            "    try:\n",
            "        import numpy as np\n",
            "        np.random.seed(seed)\n",
            "    except ImportError:\n",
            "        pass  # NumPy not installed, skip.\n",
            "\n",
            "\n",
            "def get_logger(name: str = \"app_logger\"):\n",
            "    \"\"\"\n",
            "    Returns a simple logger instance with formatting.\n",
            "    Prevents adding duplicate handlers on repeated imports.\n",
            "    \"\"\"\n",
            "    logger = logging.getLogger(name)\n",
            "\n",
            "    if not logger.handlers:\n",
            "        handler = logging.StreamHandler()\n",
            "        formatter = logging.Formatter(\n",
            "            fmt=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
            "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
            "        )\n",
            "        handler.setFormatter(formatter)\n",
            "        logger.addHandler(handler)\n",
            "\n",
            "    logger.setLevel(logging.INFO)\n",
            "    return logger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ml-intern-assessment/ml-assignment\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fehyNSJxzx5",
        "outputId": "71282ef0-c08c-44d7-a47c-3846807f9548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ml-intern-assessment/ml-assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = \"/content/ml-intern-assessment/ml-assignment:/content/ml-intern-assessment/ml-assignment/src\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ERrGWO2k0Yv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ngram_model import TrigramModel\n",
        "print(\"Import OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_I1JXfG1Ndh",
        "outputId": "d4e6c884-1b9a-477c-b17a-4a3fccf062d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xpW6TUZ0cxR",
        "outputId": "8a5353d7-0fde-4946-e90d-11544827171f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4wRnzVUwAdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "744QA2A9wAgF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}